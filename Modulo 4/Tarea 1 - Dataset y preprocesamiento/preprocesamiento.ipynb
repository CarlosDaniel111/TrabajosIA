{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ebf732",
   "metadata": {},
   "source": [
    "# Preprocesamiento para Clasificador de Emociones\n",
    "\n",
    "## Integrantes:\n",
    "- Beltran Medina Carlos Daniel\n",
    "- Beltran Ontiveros Karen Valeria\n",
    "\n",
    "## Dataset\n",
    "https://www.kaggle.com/datasets/yousefmohamed20/sentiment-images-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9dfaa4",
   "metadata": {},
   "source": [
    "### 1. Importar las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a55d2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb788e3",
   "metadata": {},
   "source": [
    "### 2. Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc8dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1148 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "ruta_dataset = \"../dataset\"\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    ruta_dataset,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288372e",
   "metadata": {},
   "source": [
    "### 3. Preprocesar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # Cambios de luz\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.random_brightness(image, max_delta=0.05)\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.random_contrast(image, lower=0.95, upper=1.05)\n",
    "\n",
    "    # Rotaci√≥n aleatoria\n",
    "    image = tf.image.rot90(image, tf.random.uniform([], 0, 4, dtype=tf.int32))\n",
    "\n",
    "    # Zoom in/out con padding y crop\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 270, 270)\n",
    "    image = tf.image.random_crop(image, size=[256, 256, 3])\n",
    "\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset_preprocesado = (\n",
    "    dataset\n",
    "    .unbatch()\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
